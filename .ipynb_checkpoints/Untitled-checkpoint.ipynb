{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "from tensorflow import random\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-16T08:42:01.000Z</td>\n",
       "      <td>We must pass The Great Filter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-09T20:00:00.000Z</td>\n",
       "      <td>“The future of cars can and will be electric i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-08T14:36:14.000Z</td>\n",
       "      <td>We put the 2020 @Tesla Model Y Long Range elec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-07T22:47:59.000Z</td>\n",
       "      <td>Starman, last seen leaving Earth, made its fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-06T12:33:30.000Z</td>\n",
       "      <td>Deployment of 60 Starlink satellites confirmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-10-06T11:44:54.000Z</td>\n",
       "      <td>4th flight &amp; landing for this booster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-10-06T11:24:42.000Z</td>\n",
       "      <td>5 minutes from launch. Looks good so far.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-10-05T23:42:20.000Z</td>\n",
       "      <td>Turn volume to 11 &amp; play Powerglide in your Tesla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-10-05T23:22:49.000Z</td>\n",
       "      <td>Music volume on a Tesla goes to 11, because it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-10-05T22:38:33.000Z</td>\n",
       "      <td>Rewatched Young Frankenstein this weekend. Sti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date                                               text\n",
       "0  2020-08-16T08:42:01.000Z                      We must pass The Great Filter\n",
       "1  2020-10-09T20:00:00.000Z  “The future of cars can and will be electric i...\n",
       "2  2020-10-08T14:36:14.000Z  We put the 2020 @Tesla Model Y Long Range elec...\n",
       "3  2020-10-07T22:47:59.000Z  Starman, last seen leaving Earth, made its fir...\n",
       "4  2020-10-06T12:33:30.000Z     Deployment of 60 Starlink satellites confirmed\n",
       "5  2020-10-06T11:44:54.000Z              4th flight & landing for this booster\n",
       "6  2020-10-06T11:24:42.000Z          5 minutes from launch. Looks good so far.\n",
       "7  2020-10-05T23:42:20.000Z  Turn volume to 11 & play Powerglide in your Tesla\n",
       "8  2020-10-05T23:22:49.000Z  Music volume on a Tesla goes to 11, because it...\n",
       "9  2020-10-05T22:38:33.000Z  Rewatched Young Frankenstein this weekend. Sti..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Load the dataset\n",
    "file_path = Path(\"C:\\\\Users\\\\Zach.000\\\\Documents\\\\SMUFinTech\\\\GitHub\\\\Portfolio\\\\project-3\\\\Resources\\\\elonmusk_tweets.csv\")\n",
    "df_tweets = pd.read_csv(file_path)\n",
    "df_tweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Zach.000\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TESLA Tweet sentiment scores DataFrame\n",
    "#tweet_sentiments = []\n",
    "\n",
    "#for text in df_tweets[\"text\"]:\n",
    "   # try:\n",
    "    #    text = df_tweets[\"text\"]\n",
    "     #   date = df_tweets['date']\n",
    "      #  sentiment = analyzer.polarity_scores(text)\n",
    "       # compound = sentiment[\"compound\"]\n",
    "        #pos = sentiment[\"pos\"]\n",
    "        #neu = sentiment[\"neu\"]\n",
    "        #neg = sentiment[\"neg\"]\n",
    "        \n",
    "        #tweet_sentiments.append({\n",
    "         #   \"text\": text,\n",
    "          #  \"date\": date,\n",
    "           # \"compound\": compound,\n",
    "            #\"positive\": pos,\n",
    "            #\"negative\": neg,\n",
    "            #\"neutral\": neu\n",
    "            \n",
    "        #})\n",
    "        \n",
    "   # except AttributeError:\n",
    "    #    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "#sentiment_df = pd.DataFrame(tweet_sentiments)\n",
    "\n",
    "#sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder DataFrame columns\n",
    "#cols = [\"date\", \"text\", \"compound\", \"positive\", \"negative\", \"neutral\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment_df = sentiment_df[cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the X and y vectors\n",
    "X = reviews_df[\"full_review_text\"].values\n",
    "y = reviews_df[\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train, test, and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download/Update the VADER Lexicon\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two lists to store vader sentiment scoring\n",
    "y_vader_pred = []\n",
    "y_vader_prob = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Score sentiment of test set using Vader\n",
    "for comment in X_test:\n",
    "    y_vader_prob.append(analyzer.polarity_scores(comment)[\"pos\"])\n",
    "    sentiment_score = analyzer.polarity_scores(comment)[\"compound\"]\n",
    "    if sentiment_score >= 0.1:\n",
    "        y_vader_pred.append(1)\n",
    "    else:\n",
    "        y_vader_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Normalizing data using MinMaxScaler from sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(np.array(y_vader_prob).reshape(-1,1))\n",
    "y_vader_prob_norm = scaler.transform(np.array(y_vader_prob).reshape(-1,1))\n",
    "y_vader_prob_norm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Using a comprehension list\n",
    "normalized = [(x - min(y_vader_prob)) / (max(y_vader_prob) - min(y_vader_prob))\n",
    "              for x in y_vader_prob]\n",
    "normalized[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Import Keras modules for data encoding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Tokenizer and fit it with the X text data\n",
    "tokenizer = Tokenizer(lower=True)\n",
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Print the first five elements of the encoded vocabulary\n",
    "for token in list(tokenizer.word_index)[:5]:\n",
    "    print(f\"word: '{token}', token: {tokenizer.word_index[token]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the text data to numerical sequences\n",
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# Contrast a sample numerical sequence with its text version\n",
    "print(\"**Text comment**\")\n",
    "print({X[0]})\n",
    "print(\"**Numerical sequence representation**\")\n",
    "print(X_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pad_sequences method from Keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding sequences\n",
    "X_pad = pad_sequences(X_seq, maxlen=140, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Creating training, validation, and testing sets using the encoded data\n",
    "X_train_rnn, X_test_rnn, y_train_rnn, y_test_rnn = train_test_split(X_pad, y)\n",
    "\n",
    "X_train_rnn, X_val_rnn, y_train_rnn, y_val_rnn = train_test_split(X_train_rnn, y_train_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras modules for model creation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model set-up\n",
    "vocabulary_size = len(tokenizer.word_counts.keys()) + 1\n",
    "max_words = 140\n",
    "embedding_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Define the LSTM RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 1\n",
    "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "\n",
    "# Layer 2\n",
    "model.add(LSTM(units=280))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Compile the model\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.TruePositives(name=\"tp\"),\n",
    "        tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "        tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
    "        tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "batch_size = 1000\n",
    "epochs = 10\n",
    "model.fit(\n",
    "    X_train_rnn,\n",
    "    y_train_rnn,\n",
    "    validation_data=(X_val_rnn, y_val_rnn),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Predict classes using the testing data\n",
    "y_rnn_pred = model.predict_classes(X_test_rnn, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Vader Accuracy: %.2f\" % (accuracy_score(y_test, y_vader_pred)))\n",
    "print(\"RNN LSTM Accuracy %.2f\" % (accuracy_score(y_test_rnn, y_rnn_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the confusion_matrix method from sklearn\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrtix metrics from Vader\n",
    "tn_vader, fp_vader, fn_vader, tp_vader = confusion_matrix(y_test, y_vader_pred).ravel()\n",
    "\n",
    "# Dataframe to display confusion matrix from Vader\n",
    "cm_vader_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Positive(1)\": [f\"TP={tp_vader}\", f\"FP={fp_vader}\"],\n",
    "        \"Negative(0)\": [f\"FN={fn_vader}\", f\"TN={tn_vader}\"],\n",
    "    },\n",
    "    index=[\"Positive(1)\", \"Negative(0)\"],\n",
    ")\n",
    "cm_vader_df.index.name = \"Actual\"\n",
    "cm_vader_df.columns.name = \"Predicted\"\n",
    "print(\"Confusion Matrix from Vader\")\n",
    "display(cm_vader_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrtix metrics from the RNN LSTM model\n",
    "tn_rnn, fp_rnn, fn_rnn, tp_rnn = confusion_matrix(y_test_rnn, y_rnn_pred).ravel()\n",
    "\n",
    "# Dataframe to display confusion matrix from the RNN LSTM model\n",
    "cm_rnn_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Positive(1)\": [f\"TP={tp_rnn}\", f\"FP={fp_rnn}\"],\n",
    "        \"Negative(0)\": [f\"FN={fn_rnn}\", f\"TN={tn_rnn}\"],\n",
    "    },\n",
    "    index=[\"Positive(1)\", \"Negative(0)\"],\n",
    ")\n",
    "cm_rnn_df.index.name = \"Actual\"\n",
    "cm_rnn_df.columns.name = \"Predicted\"\n",
    "print(\"Confusion Matrix from the RNN LSTM Model\")\n",
    "display(cm_rnn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Import the classification_report method from sklearn\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display classification report for Vader\n",
    "print(\"Classification Report for Vader\")\n",
    "print(classification_report(y_vader_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Display classification report for the RNN LSTM Model\n",
    "print(\"Classification Report for the RNN LSTM Model\")\n",
    "print(classification_report(y_rnn_pred, y_test_rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the roc_curve and auc metrics from sklearn\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Data for ROC Curve - VADER\n",
    "fpr_test_vader, tpr_test_vader, thresholds_test_vader = roc_curve(y_test, y_vader_prob_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # AUC for VADER\n",
    "auc_test_vader = auc(fpr_test_vader, tpr_test_vader)\n",
    "auc_test_vader = round(auc_test_vader, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to plot ROC Curve for VADER\n",
    "roc_df_test_vader = pd.DataFrame({\"FPR Test\": fpr_test_vader, \"TPR Test\": tpr_test_vader,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_df_test_vader.plot(\n",
    "    x=\"FPR Test\",\n",
    "    y=\"TPR Test\",\n",
    "    color=\"red\",\n",
    "    style=\"--\",\n",
    "    xlim=([-0.05, 1.05]),\n",
    "    title=f\"Test ROC Curve - Vader (AUC={auc_test_vader})\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions to feed the roc_curve module\n",
    "test_predictions_rnn = model.predict(X_test_rnn, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Data for ROC Curve - RNN LSTM Model\n",
    "fpr_test_rnn, tpr_test_rnn, thresholds_test_rnn = roc_curve(y_test_rnn, test_predictions_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC for the RNN LSTM Model\n",
    "auc_test_rnn = auc(fpr_test_rnn, tpr_test_rnn)\n",
    "auc_test_rnn = round(auc_test_rnn, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to plot ROC Curve for the RNN LSTM model\n",
    "roc_df_test_rnn = pd.DataFrame({\"FPR Test\": fpr_test_rnn, \"TPR Test\": tpr_test_rnn,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_df_test_rnn.plot(\n",
    "    x=\"FPR Test\",\n",
    "    y=\"TPR Test\",\n",
    "    color=\"blue\",\n",
    "    style=\"--\",\n",
    "    xlim=([-0.05, 1.05]),\n",
    "    title=f\"Test ROC Curve (AUC={auc_test_rnn})\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
